[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/starwars/starwars_df.html",
    "href": "posts/starwars/starwars_df.html",
    "title": "Starwars",
    "section": "",
    "text": "Let’s analyze the starwars data:"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "href": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "title": "Starwars",
    "section": "Variable Description for starwars data.frame",
    "text": "Variable Description for starwars data.frame\nThe following describes the variables in the starwars data.frame.\n\nfilms List of films the character appeared in\nname Name of the character\nspecies Name of species\nheight Height (cm)\nmass Weight (kg)\nhair_color, skin_color, eye_color Hair, skin, and eye colors\nbirth_year Year born (BBY = Before Battle of Yavin)\nsex The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).\ngender The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).\nhomeworld Name of homeworld"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#human-vs.-droid",
    "href": "posts/starwars/starwars_df.html#human-vs.-droid",
    "title": "Starwars",
    "section": "Human vs. Droid",
    "text": "Human vs. Droid\n\nggplot(data = \n         starwars %>% \n         filter(species %in% c(\"Human\", \"Droid\"))) +\n  geom_boxplot(aes(x = species, y = mass, \n                   fill = species),\n               show.legend = FALSE)"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html",
    "href": "posts/beer-markets/beer-markets.html",
    "title": "Beer Markets",
    "section": "",
    "text": "Let’s analyze the beer_data data:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "href": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "title": "Beer Markets",
    "section": "Variable Description for beer_data data.frame",
    "text": "Variable Description for beer_data data.frame\nThe following describes the variables in the beer_data data.frame.\n\nhh: Household identifier\n_purchase_desc: Description of the purchase\nquantity: The quantity of beer purchased\nbrand: The brand of beer\ndollar_spent: The amount spent\nbeer_floz: Fluid ounces of beer\nprice_per_floz: Price per fluid ounce\ncontainer: Type of container\npromo: Whether the purchase was on promotion\nmarket: The market where the purchase was made\nDemographics: age, employment status, degree, class of worker (cow), race, and household information like microwave, dishwasher, tvcable, singlefamilyhome, and npeople (number of people in the household)"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "href": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "title": "Beer Markets",
    "section": "Purchase Patterns",
    "text": "Purchase Patterns\nWe’ll explore the purchase patterns in the dataset. This includes understanding the most popular brands, the average quantity purchased, and spending habits across different markets. Here are some specific analyses we can perform:\n\nCalculate the total quantity and spending for each brand.\nFind the average quantity purchased and average spending per purchase.\nCompare the total spending across different markets.\n\nI’ll begin with these analyses and create visualizations to help us understand the data better. Let’s start by calculating the total quantity and spending for each brand.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Reading the CSV file\nbeer_data = pd.read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")\n\n# Setting up the visualisation settings\nsns.set(style=\"whitegrid\")\n\n# Calculate total quantity and spending for each brand\nbrand_summary = beer_data.groupby('brand').agg({'quantity':'sum', 'dollar_spent':'sum'}).reset_index()\n\n# Sort by total quantity and spending\nbrand_summary_sorted_quantity = brand_summary.sort_values('quantity', ascending=False)\nbrand_summary_sorted_spent = brand_summary.sort_values('dollar_spent', ascending=False)\n\n\n# Plotting total quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=brand_summary_sorted_quantity, palette='viridis')\nplt.title('Total Quantity of Beer Purchased by Brand')\nplt.xlabel('Total Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting total spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=brand_summary_sorted_spent, palette='viridis')\nplt.title('Total Spending on Beer by Brand')\nplt.xlabel('Total Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar charts above display the total quantity of beer purchased and the total spending by brand. From the looks of it, certain brands dominate in terms of quantity sold and total spending, indicating their popularity.\nNow, let’s calculate the average quantity purchased and average spending per purchase. For this, we’ll consider each row in the dataset as a separate purchase and compute the averages accordingly.\n\n# Calculate average quantity purchased and average spending per purchase\naverage_purchase = beer_data.groupby('brand').agg({\n    'quantity': 'mean', \n    'dollar_spent': 'mean'\n}).reset_index()\n\n# Sort by average quantity and average spending\naverage_purchase_sorted_quantity = average_purchase.sort_values('quantity', ascending=False)\naverage_purchase_sorted_spent = average_purchase.sort_values('dollar_spent', ascending=False)\n\n# Plotting average quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=average_purchase_sorted_quantity, palette='viridis')\nplt.title('Average Quantity of Beer Purchased by Brand')\nplt.xlabel('Average Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting average spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=average_purchase_sorted_spent, palette='viridis')\nplt.title('Average Spending on Beer by Brand')\nplt.xlabel('Average Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe visualizations above depict the average quantity of beer purchased per brand and the average spending per brand. This shows which brands tend to be bought in larger quantities on average and which brands tend to have higher spending per purchase, which could be indicative of their price point or the purchase of premium products.\nNext, we’ll look at the total spending across different markets to see if there are any notable differences in spending habits geographically. To do this, we’ll sum up the spending in each market and visualize it.\n\n# Calculate total spending in each market\nmarket_spending_summary = beer_data.groupby('market').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nmarket_spending_summary_sorted = market_spending_summary.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending in each market\nplt.figure(figsize=(12, 10))\nsns.barplot(x='dollar_spent', y='market', data=market_spending_summary_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Market')\nplt.xlabel('Total Spending')\nplt.ylabel('Market')\nplt.show()\n\n\n\n\nThe bar chart illustrates the total spending on beer by market, showcasing the differences in spending habits across various regions. Some markets have significantly higher spending, which could be due to a variety of factors including market size, consumer preferences, or economic factors.\nNow, let’s move on to the second analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "href": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "title": "Beer Markets",
    "section": "Demographic Analysis",
    "text": "Demographic Analysis\nWe will examine which demographics are buying what kind of beer and whether spending habits vary by demographics such as age, employment, and race. For this, we could look at:\n\nSpending by age group\nSpending by employment status\nSpending by race\n\nI’ll start by analyzing spending by age group.\n\n# Calculate total spending by age group\nage_group_spending = beer_data.groupby('age').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nage_group_spending_sorted = age_group_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by age group\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='age', data=age_group_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Age Group')\nplt.xlabel('Total Spending')\nplt.ylabel('Age Group')\nplt.show()\n\n\n\n\nThe bar chart demonstrates the total spending on beer segmented by age group, highlighting which age groups spend the most on beer. It appears that certain age groups are more dominant in beer spending, which may align with the purchasing power or preferences of those groups.\nNext, we will examine spending by employment status.\n\n# Calculate total spending by employment status\nemployment_spending = beer_data.groupby('employment').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nemployment_spending_sorted = employment_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by employment status\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='employment', data=employment_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Employment Status')\nplt.xlabel('Total Spending')\nplt.ylabel('Employment Status')\nplt.show()\n\n\n\n\nThe visualization shows the total spending on beer by employment status. We can see that certain employment groups, such as full-time workers, are spending more on beer, which might be related to their disposable income.\nFinally, let’s look at spending by race to complete the demographic analysis.\n\n# Calculate total spending by race\nrace_spending = beer_data.groupby('race').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nrace_spending_sorted = race_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by race\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='race', data=race_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Race')\nplt.xlabel('Total Spending')\nplt.ylabel('Race')\nplt.show()\n\n\n\n\nThe bar chart above indicates the total spending on beer broken down by race, highlighting which racial groups account for the most beer spending within the dataset. This could reflect both the demographics of the regions where the data was collected and cultural preferences regarding beer.\nNow, let’s proceed to the third analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "href": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "title": "Beer Markets",
    "section": "Price Sensitivity",
    "text": "Price Sensitivity\nWe’ll look at the price per fluid ounce and see if there are any trends or correlations with the quantity purchased or the brand popularity. To do this, we’ll calculate the average price per fluid ounce for each brand and then visualize how this relates to the average quantity purchased and the total quantity purchased by brand.\nFirst, let’s calculate the average price per fluid ounce for each brand.\n\n# Calculate average price per fluid ounce for each brand\nbrand_price_sensitivity = beer_data.groupby('brand').agg({\n    'price_per_floz': 'mean', \n    'quantity': 'sum'\n}).reset_index()\n\n# Sort by price per fluid ounce\nbrand_price_sensitivity_sorted = brand_price_sensitivity.sort_values('price_per_floz', ascending=True)\n\n# Plotting average price per fluid ounce for each brand and the total quantity purchased\nfig, ax1 = plt.subplots(figsize=(12, 10))\n\ncolor = 'tab:red'\nax1.set_xlabel('Brand')\nax1.set_ylabel('Average Price per Fluid Ounce', color=color)\nax1.bar(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['price_per_floz'], color=color)\nax1.tick_params(axis='y', labelcolor=color)\nax1.set_xticklabels(brand_price_sensitivity_sorted['brand'], rotation=90)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\ncolor = 'tab:blue'\nax2.set_ylabel('Total Quantity Purchased', color=color)  # we already handled the x-label with ax1\nax2.plot(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['quantity'], color=color)\nax2.tick_params(axis='y', labelcolor=color)\n\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nplt.title('Average Price per Fluid Ounce & Total Quantity Purchased by Brand')\nplt.show()\n\n\n\n\nIn the visualization, we have a bar graph showing the average price per fluid ounce for each brand (in red) and a line graph showing the total quantity purchased for each brand (in blue). This gives us a sense of whether there’s a relationship between the price and the quantity purchased. The x-axis labels are quite compressed due to the number of brands, but we can still observe trends such as whether lower-priced beers tend to be purchased in larger quantities.\nLastly, let’s move to the fourth analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#promotional-impact",
    "href": "posts/beer-markets/beer-markets.html#promotional-impact",
    "title": "Beer Markets",
    "section": "Promotional Impact",
    "text": "Promotional Impact\nWe’ll assess the impact of promotions on the quantity of beer purchased. For this analysis, we can calculate the average quantity purchased with and without promotions and visualize the difference. We’ll do this for each brand to see which brands are most affected by promotions.\nLet’s begin this analysis by looking at the average quantity purchased with and without promotions for each brand.\n\n# Calculate average quantity purchased with and without promotions for each brand\npromo_impact = beer_data.groupby(['brand', 'promo']).agg({'quantity':'mean'}).reset_index()\n\n# Pivot the data to have promo and non-promo side by side for each brand\npromo_impact_pivot = promo_impact.pivot(index='brand', columns='promo', values='quantity').reset_index()\npromo_impact_pivot.columns = ['brand', 'non_promo', 'promo']\n\n# Calculate the difference in average quantity purchased between promo and non-promo\npromo_impact_pivot['promo_impact'] = promo_impact_pivot['promo'] - promo_impact_pivot['non_promo']\n\n# Sort by the impact of promo\npromo_impact_pivot_sorted = promo_impact_pivot.sort_values('promo_impact', ascending=False)\n\n# Plotting the difference in average quantity purchased between promo and non-promo for each brand\nplt.figure(figsize=(12, 10))\nsns.barplot(x='promo_impact', y='brand', data=promo_impact_pivot_sorted, palette='viridis')\nplt.title('Impact of Promotions on Average Quantity Purchased by Brand')\nplt.xlabel('Difference in Average Quantity Purchased (Promo - Non-Promo)')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar chart illustrates the impact of promotions on the average quantity of beer purchased by brand. A positive value indicates that, on average, more beer is purchased when there is a promotion compared to when there isn’t. Some brands appear to be significantly more influenced by promotions, with customers buying more when the products are on sale or promotion.\nThis comprehensive analysis has provided insights into purchase patterns, demographic preferences, price sensitivity, and the impact of promotions on beer purchases."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jocelyn Matusiak",
    "section": "",
    "text": "Jocelyn Matusiak majors in Business Administration at SUNY Genesseo. She plans to graduate in 2026 with a degree in Business Administration."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Jocelyn Matusiak",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo | Geneseo, NY  B.S. in Business Administration | Aug 2022 - May 2026  Minor in Human Resources"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Jocelyn Matusiak",
    "section": "Experience",
    "text": "Experience"
  },
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Insightful Analytics",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nDANL200-HW5-MATUSIAK-JOCELYN.qmd\n\n\n\n\n\n\n\n\n\nNov 11, 2023\n\n\nJocelyn Matusiak\n\n\n12 min\n\n\n\n\n\n\n  \n\n\n\n\nSpotify\n\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\njocelyn matusiak\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\nrestaurants\n\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\njocelyn matusiak\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\nbeer markets\n\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nJocelyn Matusiak\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\nOct 27, 2023\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "DANL Project",
    "section": "",
    "text": "library(tidyverse)\nlibrary(hrbrthemes)\nlibrary(skimr)"
  },
  {
    "objectID": "project.html#summary-statistics",
    "href": "project.html#summary-statistics",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.1 Summary Statistics",
    "text": "2.1 Summary Statistics\n\nmpg &lt;- ggplot2::mpg\n\n\n\n\n  \n\n\n\nskim(mpg) %&gt;% \n  select(-n_missing)\n\n\nData summary\n\n\nName\nmpg\n\n\nNumber of rows\n234\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\nskim_variable\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmanufacturer\n1\n4\n10\n0\n15\n0\n\n\nmodel\n1\n2\n22\n0\n38\n0\n\n\ntrans\n1\n8\n10\n0\n10\n0\n\n\ndrv\n1\n1\n1\n0\n3\n0\n\n\nfl\n1\n1\n1\n0\n5\n0\n\n\nclass\n1\n3\n10\n0\n7\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndispl\n1\n3.47\n1.29\n1.6\n2.4\n3.3\n4.6\n7\n▇▆▆▃▁\n\n\nyear\n1\n2003.50\n4.51\n1999.0\n1999.0\n2003.5\n2008.0\n2008\n▇▁▁▁▇\n\n\ncyl\n1\n5.89\n1.61\n4.0\n4.0\n6.0\n8.0\n8\n▇▁▇▁▇\n\n\ncty\n1\n16.86\n4.26\n9.0\n14.0\n17.0\n19.0\n35\n▆▇▃▁▁\n\n\nhwy\n1\n23.44\n5.95\n12.0\n18.0\n24.0\n27.0\n44\n▅▅▇▁▁"
  },
  {
    "objectID": "project.html#mpg-and-a-type-of-cars",
    "href": "project.html#mpg-and-a-type-of-cars",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.2 MPG and a Type of Cars",
    "text": "2.2 MPG and a Type of Cars\nThe following boxplot shows how the distribution of highway MPG (hwy) varies by a type of cars (class) :blue_car: :truck: :minibus:.\n\nggplot(data = mpg) +\n  geom_boxplot(aes(x = class, y = hwy, fill = class),\n               show.legend = F) +\n  labs(x = \"Class\", y = \"Highway\\nMPG\")"
  },
  {
    "objectID": "posts/restaurants/restaurants.html",
    "href": "posts/restaurants/restaurants.html",
    "title": "restaurants",
    "section": "",
    "text": "Let’s analyze the res data:\n\nres &lt;- read_csv(\"https://bcdanl.github.io/data/DOHMH_NYC_Restaurant_Inspection.csv\")\n\nrmarkdown::paged_table(res)"
  },
  {
    "objectID": "posts/beermarkets/beer-markets.html",
    "href": "posts/beermarkets/beer-markets.html",
    "title": "Spotify",
    "section": "",
    "text": "Let’s analyze the spotify data:\n\nspotify &lt;- read_csv(\"https://bcdanl.github.io/data/spotify_all.csv\")\n\nrmarkdown::paged_table(spotify)"
  },
  {
    "objectID": "posts/beermarkets/spotify.html",
    "href": "posts/beermarkets/spotify.html",
    "title": "Spotify",
    "section": "",
    "text": "Let’s analyze the spotify data:\n\nspotify &lt;- read_csv(\"https://bcdanl.github.io/data/spotify_all.csv\")\n\nrmarkdown::paged_table(spotify)"
  },
  {
    "objectID": "posts/post-with-code/beer_markets.html",
    "href": "posts/post-with-code/beer_markets.html",
    "title": "beer markets",
    "section": "",
    "text": "Let’s analyze the beer_markets data:\n\nbeer_markets &lt;- read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")\n\nrmarkdown::paged_table(beer_markets)"
  },
  {
    "objectID": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html",
    "href": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html",
    "title": "DANL200-HW5-MATUSIAK-JOCELYN.qmd",
    "section": "",
    "text": "library(knitr)\nlibrary(rmarkdown)\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(ggthemes)\nlibrary(hrbrthemes)"
  },
  {
    "objectID": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#variable-description",
    "href": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#variable-description",
    "title": "DANL200-HW5-MATUSIAK-JOCELYN.qmd",
    "section": "Variable description",
    "text": "Variable description\n\nplay_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play\ngame_id: Ten digit identifier for NFL game.\ndrive: Numeric drive number in the game.\nweek: Season week.\nposteam: String abbreviation for the team with possession.\nqtr: Quarter of the game (5 is overtime).\nhalf_seconds_remaining: Numeric seconds remaining in the half.\ndown: The down for the given play.\n\nBasically you get four attempts (aka downs) to move the ball 10 yards (by either running with it or passing it).\nIf you make 10 yards then you get another set of four downs.\n\npass: Binary indicator if the play was a pass play.\nwp: Estimated winning probability for the posteam given the current situation at the start of the given play."
  },
  {
    "objectID": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#q2a.",
    "href": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#q2a.",
    "title": "DANL200-HW5-MATUSIAK-JOCELYN.qmd",
    "section": "Q2a.",
    "text": "Q2a.\nIn data.frame, NFL2022_stuffs, remove observations for which values of posteam is missing.\nAnswer:\n\nNFL2022_stuffs &lt;- NFL2022_stuffs[!is.na(NFL2022_stuffs$posteam), ]"
  },
  {
    "objectID": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#q2b.",
    "href": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#q2b.",
    "title": "DANL200-HW5-MATUSIAK-JOCELYN.qmd",
    "section": "Q2b.",
    "text": "Q2b.\n\nSummarize the mean value of pass for each posteam when all the following conditions hold:\n\nwp is greater than 20% and less than 75%;\ndown is less than or equal to 2; and\nhalf_seconds_remaining is greater than 120.\n\n\nAnswer:\n\nlibrary(dplyr)\n\nresult &lt;- NFL2022_stuffs %&gt;%\n  filter(wp &gt; 0.20 & wp &lt; 0.75 & down &lt;= 2 & half_seconds_remaining &gt; 120) %&gt;%\n  group_by(posteam) %&gt;%\n  summarize(mean_pass = mean(pass, na.rm = TRUE))\n\nprint(result)\n\n# A tibble: 32 × 2\n   posteam mean_pass\n   &lt;chr&gt;       &lt;dbl&gt;\n 1 ARI         0.553\n 2 ATL         0.4  \n 3 BAL         0.520\n 4 BUF         0.604\n 5 CAR         0.458\n 6 CHI         0.420\n 7 CIN         0.657\n 8 CLE         0.491\n 9 DAL         0.474\n10 DEN         0.493\n# ℹ 22 more rows"
  },
  {
    "objectID": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#q2c.",
    "href": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#q2c.",
    "title": "DANL200-HW5-MATUSIAK-JOCELYN.qmd",
    "section": "Q2c.",
    "text": "Q2c.\n\nProvide both (1) a ggplot code with geom_point() using the resulting data.frame in Q2b and (2) a simple comments to describe the mean value of pass for each posteam.\n\nIn the ggplot, reorder the posteam categories based on the mean value of pass in ascending or in descending order.\n\n\nAnswer:\n\nlibrary(ggplot2)\n\nresult &lt;- result[order(result$mean_pass), ]\n\nggplot(result, aes(x = reorder(posteam, mean_pass), y = mean_pass)) +\n  geom_point() +\n  labs(title = \"Mean Value of Pass for Each posteam\",\n       x = \"posteam\",\n       y = \"Mean Pass Value\")"
  },
  {
    "objectID": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#q2d.",
    "href": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#q2d.",
    "title": "DANL200-HW5-MATUSIAK-JOCELYN.qmd",
    "section": "Q2d.",
    "text": "Q2d.\n\nConsider the following data.frame, NFL2022_epa:\n\nNFL2022_epa &lt;- read_csv('https://bcdanl.github.io/data/NFL2022_epa.csv')\n\n\nNFL2022_epa &lt;- read_csv('https://bcdanl.github.io/data/NFL2022_epa.csv')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplay_id\n&lt;dbl&gt;\ngame_id\n&lt;chr&gt;\ndrive\n&lt;dbl&gt;\nposteam\n&lt;chr&gt;\nreceiver\n&lt;chr&gt;\npasser\n&lt;chr&gt;\n\n\n\n\n\n43\n2022_01_BAL_NYJ\n1\nNYJ\nNA\nNA\n\n\n\n68\n2022_01_BAL_NYJ\n1\nNYJ\nNA\nNA\n\n\n\n89\n2022_01_BAL_NYJ\n1\nNYJ\nMi.Carter\nJ.Flacco\n\n\n\n115\n2022_01_BAL_NYJ\n1\nNYJ\nNA\nNA\n\n\n\n136\n2022_01_BAL_NYJ\n1\nNYJ\nNA\nJ.Flacco\n\n\n\n172\n2022_01_BAL_NYJ\n1\nNYJ\nNA\nNA\n\n\n\n202\n2022_01_BAL_NYJ\n2\nBAL\nR.Bateman\nL.Jackson\n\n\n\n230\n2022_01_BAL_NYJ\n2\nBAL\nD.Duvernay\nL.Jackson\n\n\n\n254\n2022_01_BAL_NYJ\n2\nBAL\nNA\nNA\n\n\n\n275\n2022_01_BAL_NYJ\n2\nBAL\nNA\nNA\n\n\n\n\nNext\n123456\n...\n1000\nPrevious\n1-10 of 10,000 rows | 1-6 of 7 columns\n\nVariable description for NFL2022_epa\n\nplay_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play\ngame_id: Ten digit identifier for NFL game.\ndrive: Numeric drive number in the game.\nposteam: String abbreviation for the team with possession.\npasser: Name of the player who passed a ball to a receiver by initially taking a three-step drop and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks)\nreceiver: Name of the receiver.\nepa: Expected points added (EPA) by the posteam for the given play.\n\nCreate the data.frame, NFL2022_stuffs_EPA, that includes\n\nAll the variables in the data.frame, NFL2022_stuffs;\nThe variables, passer, receiver, and epa, from the data.frame, NFL2022_epa. by joining the two data.frames.\n\nIn the resulting data.frame, NFL2022_stuffs_EPA, remove observations with NA in passer.\n\nAnswer:\n\nNFL2022_stuffs_EPA &lt;- merge(NFL2022_stuffs, NFL2022_epa)\n\nNFL2022_stuffs_EPA &lt;- subset(NFL2022_stuffs_EPA, !is.na(passer))"
  },
  {
    "objectID": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#q2e.",
    "href": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#q2e.",
    "title": "DANL200-HW5-MATUSIAK-JOCELYN.qmd",
    "section": "Q2e.",
    "text": "Q2e.\n\nProvide both (1) a single ggplot and (2) a simple comment to describe the NFL weekly trend of weekly mean value of epa for each of the following two passers,\n\n\"J.Allen\"\n\"P.Mahomes\"\n\n\nAnswer:\n\nlibrary(ggplot2)\n\npassers_data &lt;- NFL2022_stuffs_EPA %&gt;%\n  filter(passer %in% c(\"J.Allen\", \"P.Mahomes\"))\n\npassers_data$week &lt;- factor(passers_data$week, levels = unique(passers_data$week))\n\nggplot(passers_data, aes(x = week, y = epa, group = passer, color = passer)) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"NFL Weekly Trend of Mean EPA\",\n       x = \"Week\",\n       y = \"Mean EPA Value\",\n       color = \"Passer\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#q2f.",
    "href": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#q2f.",
    "title": "DANL200-HW5-MATUSIAK-JOCELYN.qmd",
    "section": "Q2f.",
    "text": "Q2f.\nCalculate the difference between the mean value of epa for \"J.Allen\" the mean value of epa for \"P.Mahomes\" for each value of week.\nAnswer:\n\nlibrary(dplyr)\n\npassers_data &lt;- NFL2022_stuffs_EPA %&gt;%\n  filter(passer %in% c(\"J.Allen\", \"P.Mahomes\"))\n\npassers_mean &lt;- passers_data %&gt;%\n  group_by(week, passer) %&gt;%\n  summarise(mean_epa = mean(epa, na.rm = TRUE))\n\npassers_wide &lt;- passers_mean %&gt;%\n  pivot_wider(names_from = passer, values_from = mean_epa)\n\npassers_wide$epa_difference &lt;- passers_wide$`J.Allen` - passers_wide$`P.Mahomes`\n\nprint(passers_wide)\n\n# A tibble: 22 × 4\n# Groups:   week [22]\n    week J.Allen P.Mahomes epa_difference\n   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;\n 1     1   0.530    0.698         -0.169 \n 2     2   0.487    0.148          0.339 \n 3     3   0.169    0.246         -0.0763\n 4     4   0.191    0.271         -0.0803\n 5     5   0.627    0.302          0.325 \n 6     6   0.307    0.133          0.173 \n 7     7  NA        0.701         NA     \n 8     8   0.224   NA             NA     \n 9     9  -0.208    0.0965        -0.304 \n10    10   0.161    0.589         -0.429 \n# ℹ 12 more rows"
  },
  {
    "objectID": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#q2g.",
    "href": "posts/welcome/DANL200-HW5-MATUSIAK-JOCELYN.html#q2g.",
    "title": "DANL200-HW5-MATUSIAK-JOCELYN.qmd",
    "section": "Q2g.",
    "text": "Q2g.\n\nSummarize the resulting data.frame in Q2d, with the following four variables:\n\nposteam: String abbreviation for the team with possession.\npasser: Name of the player who passed a ball to a receiver by initially taking a three-step drop, and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks.)\nmean_epa: Mean value of epa in 2022 for each passer\nn_pass: Number of observations for each passer\n\nThen find the top 10 NFL passers in 2022 in terms of the mean value of epa, conditioning that n_pass must be greater than or equal to the third quantile level of n_pass.\n\nAnswer:\n\nlibrary(dplyr)\n\nsummary_data &lt;- NFL2022_stuffs_EPA %&gt;%\n  group_by(posteam, passer) %&gt;%\n  summarise(mean_epa = mean(epa, na.rm = TRUE),\n            n_pass = n())\n\nquantile_threshold &lt;- quantile(summary_data$n_pass, 0.75)\n\ntop_passers &lt;- summary_data %&gt;%\n  filter(n_pass &gt;= quantile_threshold) %&gt;%\n  top_n(10, wt = mean_epa)  \n\nprint(top_passers)\n\n# A tibble: 29 × 4\n# Groups:   posteam [29]\n   posteam passer     mean_epa n_pass\n   &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;int&gt;\n 1 ARI     K.Murray     0.0163    465\n 2 ATL     M.Mariota    0.0251    370\n 3 BAL     L.Jackson    0.0549    398\n 4 BUF     J.Allen      0.172     785\n 5 CHI     J.Fields    -0.0455    469\n 6 CIN     J.Burrow     0.153     854\n 7 CLE     J.Brissett   0.0912    445\n 8 DAL     D.Prescott   0.147     529\n 9 DEN     R.Wilson    -0.0163    609\n10 DET     J.Goff       0.171     661\n# ℹ 19 more rows"
  },
  {
    "objectID": "project_files/quarto-template.html",
    "href": "project_files/quarto-template.html",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "",
    "text": "day_wise &lt;- read_csv('https://jem10126.github.io/day_wise.csv')\nnvars &lt;- format(round(ncol(day_wise), 0), \n                nsmall=0, \n                big.mark=\",\") \nnobs &lt;- format(round(nrow(day_wise), 0), \n                nsmall=0, \n                big.mark=\",\")\nThe number of variables is 12; the number of observations is 188.\nRoses are red\nviolets are blue."
  },
  {
    "objectID": "project_files/quarto-template.html#data-summary",
    "href": "project_files/quarto-template.html#data-summary",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.1 Data Summary",
    "text": "2.1 Data Summary\n\nSummary statistics (Use skimr::skim())"
  },
  {
    "objectID": "project_files/quarto-template.html#data-visualization",
    "href": "project_files/quarto-template.html#data-visualization",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.2 Data Visualization",
    "text": "2.2 Data Visualization\n\nday_wise %&gt;% \n  ggplot(aes(x = log(Deaths), \n             y = log(Recovered))) +\n  geom_point(alpha = .1,color = 'purple') +\n  geom_smooth(method = lm, se = F) +\n  theme_bw() +\n  theme(legend.position = 'top')"
  },
  {
    "objectID": "project_files/quarto-template.html#data-transformation",
    "href": "project_files/quarto-template.html#data-transformation",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.3 Data Transformation",
    "text": "2.3 Data Transformation\n\nday_wise1 &lt;- day_wise %&gt;% \n  group_by(Deaths, Recovered) %&gt;% \n  summarise(Recovered_tot = sum(Recovered, na.rm = T),\n            Deaths_mean = round(mean(Deaths, na.rm = T), 2),\n            .groups = \"drop\")"
  },
  {
    "objectID": "project_files/quarto-template.html#analysis",
    "href": "project_files/quarto-template.html#analysis",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.4 Analysis",
    "text": "2.4 Analysis"
  },
  {
    "objectID": "project_files/quarto-template.html#quotes",
    "href": "project_files/quarto-template.html#quotes",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.5 Quotes",
    "text": "2.5 Quotes\n\nQuote with &gt;\n\n\n“The truth is rarely pure and never simple.”\n— Oscar Wilde"
  },
  {
    "objectID": "project_files/quarto-template.html#inserting-figures",
    "href": "project_files/quarto-template.html#inserting-figures",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.6 Inserting Figures",
    "text": "2.6 Inserting Figures\nFor a demonstration of a DANL tiger, see Figure 1.\n\n\n\n\n\nFigure 1: DANL Tiger"
  },
  {
    "objectID": "project_files/quarto-template.html#inserting-a-html-page",
    "href": "project_files/quarto-template.html#inserting-a-html-page",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.7 Inserting a HTML page",
    "text": "2.7 Inserting a HTML page"
  },
  {
    "objectID": "project.html#introduction",
    "href": "project.html#introduction",
    "title": "DANL Project",
    "section": "0.1 Introduction",
    "text": "0.1 Introduction\n\nWhy does this project matter?\nThis project matters because it assess the rate at which people are contracting and healing from the COVID-19 virus at a daily rate.\nOur data visualization entails both Deaths and Recovered are increasing at an exponential rate. This provides the assumption that while many may be dying there are a greater amount recovering. In the real world this provides hope for those who are suffering from the virus. Our data transformation further proves the point that there are more total recovered per day than the mean amount of deaths."
  },
  {
    "objectID": "project.html#data",
    "href": "project.html#data",
    "title": "DANL Project",
    "section": "1.1 Data",
    "text": "1.1 Data"
  },
  {
    "objectID": "project.html#data-summary",
    "href": "project.html#data-summary",
    "title": "DANL Project",
    "section": "0.3 Data Summary",
    "text": "0.3 Data Summary\n\nSummary statistics (Use skimr::skim(day_wise))\n\nWe are now performing summary statistics on our data set. We use the skim () code to find the mean, median, minimum, maximum, and quantile values. This gives us an overview of our dataset and helps us determine relationships between our variables.\n\n\n\nskimr::skim(day_wise)\n\n\nData summary\n\n\nName\nday_wise\n\n\nNumber of rows\n188\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nDate\n1\n\n\nnumeric\n11\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nDate\n0\n1\n2020-01-22\n2020-07-27\n2020-04-24\n188\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nConfirmed\n0\n1\n4406960.01\n4757988.32\n555.00\n112191.00\n2848733.00\n7422045.50\n16480485.00\n▇▃▂▂▁\n\n\nDeaths\n0\n1\n230770.76\n217929.09\n17.00\n3935.00\n204190.00\n418634.50\n654036.00\n▇▂▃▃▂\n\n\nRecovered\n0\n1\n2066001.22\n2627976.39\n28.00\n60441.25\n784784.00\n3416395.75\n9468087.00\n▇▂▁▁▁\n\n\nActive\n0\n1\n2110188.03\n1969670.45\n510.00\n58641.75\n1859759.00\n3587015.25\n6358362.00\n▇▃▃▂▂\n\n\nNew cases\n0\n1\n87771.02\n75295.29\n0.00\n5568.50\n81114.00\n131502.50\n282756.00\n▇▇▃▂▂\n\n\nNew deaths\n0\n1\n3478.82\n2537.74\n0.00\n250.75\n4116.00\n5346.00\n9966.00\n▇▃▇▃▁\n\n\nNew recovered\n0\n1\n50362.02\n56090.89\n0.00\n2488.25\n30991.50\n79706.25\n284394.00\n▇▂▂▁▁\n\n\nDeaths / 100 Cases\n0\n1\n4.86\n1.58\n2.04\n3.51\n4.85\n6.30\n7.18\n▅▅▆▅▇\n\n\nRecovered / 100 Cases\n0\n1\n34.34\n16.21\n1.71\n22.78\n35.68\n48.95\n57.45\n▃▃▆▅▇\n\n\nDeaths / 100 Recovered\n0\n1\n22.10\n22.57\n6.26\n9.65\n15.38\n25.34\n134.43\n▇▁▁▁▁\n\n\nNo. of countries\n0\n1\n144.35\n65.18\n6.00\n101.25\n184.00\n187.00\n187.00\n▂▁▁▁▇"
  },
  {
    "objectID": "project.html#data-1",
    "href": "project.html#data-1",
    "title": "DANL Project",
    "section": "1.3 Data",
    "text": "1.3 Data\n\nskimr::skim(day_wise)\n\n\nData summary\n\n\nName\nday_wise\n\n\nNumber of rows\n188\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nDate\n1\n\n\nnumeric\n11\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nDate\n0\n1\n2020-01-22\n2020-07-27\n2020-04-24\n188\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nConfirmed\n0\n1\n4406960.01\n4757988.32\n555.00\n112191.00\n2848733.00\n7422045.50\n16480485.00\n▇▃▂▂▁\n\n\nDeaths\n0\n1\n230770.76\n217929.09\n17.00\n3935.00\n204190.00\n418634.50\n654036.00\n▇▂▃▃▂\n\n\nRecovered\n0\n1\n2066001.22\n2627976.39\n28.00\n60441.25\n784784.00\n3416395.75\n9468087.00\n▇▂▁▁▁\n\n\nActive\n0\n1\n2110188.03\n1969670.45\n510.00\n58641.75\n1859759.00\n3587015.25\n6358362.00\n▇▃▃▂▂\n\n\nNew cases\n0\n1\n87771.02\n75295.29\n0.00\n5568.50\n81114.00\n131502.50\n282756.00\n▇▇▃▂▂\n\n\nNew deaths\n0\n1\n3478.82\n2537.74\n0.00\n250.75\n4116.00\n5346.00\n9966.00\n▇▃▇▃▁\n\n\nNew recovered\n0\n1\n50362.02\n56090.89\n0.00\n2488.25\n30991.50\n79706.25\n284394.00\n▇▂▂▁▁\n\n\nDeaths / 100 Cases\n0\n1\n4.86\n1.58\n2.04\n3.51\n4.85\n6.30\n7.18\n▅▅▆▅▇\n\n\nRecovered / 100 Cases\n0\n1\n34.34\n16.21\n1.71\n22.78\n35.68\n48.95\n57.45\n▃▃▆▅▇\n\n\nDeaths / 100 Recovered\n0\n1\n22.10\n22.57\n6.26\n9.65\n15.38\n25.34\n134.43\n▇▁▁▁▁\n\n\nNo. of countries\n0\n1\n144.35\n65.18\n6.00\n101.25\n184.00\n187.00\n187.00\n▂▁▁▁▇"
  },
  {
    "objectID": "project.html#data-visualization",
    "href": "project.html#data-visualization",
    "title": "DANL Project",
    "section": "0.4 Data Visualization",
    "text": "0.4 Data Visualization\n\nOur plot represents the relationship between the logarithmic of deaths and the logarithmic of recoveries for the daily number of covid cases. For this section we decided to create a scatterplot using the geom_point () code. Along with that we used geom_smooth () to create a second line to help determine the overall pattern of our data. To better the aesthetics of our graph using the theme () code.\n\n\nday_wise %&gt;% \n  ggplot(aes(x = log(Deaths), \n             y = log(Recovered))) +\n  geom_point(alpha = .1,color = 'purple') +\n  geom_smooth(method = lm, se = F) +\n  theme_bw() +\n  theme(legend.position = 'top')"
  },
  {
    "objectID": "project.html#data-transformation",
    "href": "project.html#data-transformation",
    "title": "DANL Project",
    "section": "0.5 Data Transformation",
    "text": "0.5 Data Transformation\n\nday_wise1 &lt;- day_wise %&gt;% \n  group_by(Deaths, Recovered) %&gt;% \n  summarise(Recovered_tot = sum(Recovered, na.rm = T),\n            Deaths_mean = round(mean(Deaths, na.rm = T), 2),\n            .groups = \"drop\")"
  },
  {
    "objectID": "project.html#group-relevancy",
    "href": "project.html#group-relevancy",
    "title": "DANL Project",
    "section": "1.1 Group relevancy",
    "text": "1.1 Group relevancy\nWe wanted to include how much Sophia has helped in our project while not being able to do it herself. She has attended all meetings with us as a group and helped us whenever we needed extra assistance."
  },
  {
    "objectID": "project.html#about-this-project",
    "href": "project.html#about-this-project",
    "title": "DANL Project",
    "section": "0.2 About this project:",
    "text": "0.2 About this project:\n\nWe initiated the process by generating a fresh dataset in R-studio, utilizing the path name of the “Day-Wise Covid-19” dataset. Below, you will find the resulting table produced through our code. The table is specifically designed to highlight the daily number of COVID-19 cases, as well as the status of those who were diagnosed - whether they have recovered, passed away, or are still actively ill.\n\n##Data\n\nday_wise &lt;- read_csv('https://jem10126.github.io/day_wise.csv')\nnvars &lt;- format(round(ncol(day_wise), 0), \n                nsmall=0, \n                big.mark=\",\") \nnobs &lt;- format(round(nrow(day_wise), 0), \n                nsmall=0, \n                big.mark=\",\")\n\n\nHere is the paged table using rmarkdown::paged_table() with the results = 'asis' chunk option.\n\n\n\n\n  \n\n\n\nThe number of variables is 12; the number of observations is 188."
  }
]